{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hemanthreddy31/machinelearning/blob/main/Lab3_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3yfry25JgZK"
      },
      "source": [
        "# Data augmentation\n",
        "\n",
        "FMML Module 1, Lab 3<br>\n",
        " Module Coordinator: Thrupthi Ann John thrupthi.ann@research.iiit.ac.in <br>\n",
        " Release date: 18 October 2021 <br>\n",
        "\n",
        " In this lab, we will see how augmentation of data samples help in improving the machine learning performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZU8_elooqP0"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "# set randomseed\n",
        "rng = np.random.default_rng(seed=42)\n",
        "from sklearn.utils.extmath import cartesian\n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5pHYogSMHiE"
      },
      "source": [
        "Augmentation is useful when we have less training data available. Augmentation allows us to 'create' a larger dataset programatically. \n",
        "\n",
        "For this lab we will use a subset of MNIST that is very small, to better understand the effect of augmentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJvmWJ58ovx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85e906d-e19a-48ca-beb6-8cc0c772f2af"
      },
      "source": [
        "#loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "train_X = train_X/255\n",
        "test_X = test_X/255\n",
        "\n",
        "train_X = train_X[::1200,:,:].copy() # subsample. Otherwise it will take too long!\n",
        "train_y = train_y[::1200].copy() # do the same to the labels\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XamH6z1Rt7S"
      },
      "source": [
        "Let us borrow a few functions from the previous labs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk2W5_3BRLMS"
      },
      "source": [
        "def NN1(traindata, trainlabel, query):\n",
        "  diff  = traindata - query  # find the difference between features. Numpy automatically takes care of the size here \n",
        "  sq = diff*diff # square the differences\n",
        "  dist = sq.sum(1) # add up the squares\n",
        "  label = trainlabel[np.argmin(dist)] # our predicted label is the label of the training data which has the least distance from the query\n",
        "  return label\n",
        "\n",
        "def NN(traindata, trainlabel, testdata):\n",
        "  # we will run nearest neighbour for each sample in the test data \n",
        "  # and collect the predicted classes in an array using list comprehension\n",
        "  traindata = traindata.reshape(-1, 28*28)\n",
        "  testdata = testdata.reshape(-1,28*28)\n",
        "  predlabel = np.array([NN1(traindata, trainlabel, i) for i in testdata])\n",
        "  return predlabel\n",
        "\n",
        "def Accuracy(gtlabel, predlabel):\n",
        "  assert len(gtlabel)==len(predlabel), \"Length of the groundtruth labels and predicted labels should be the same\"\n",
        "  correct = (gtlabel==predlabel).sum() # count the number of times the groundtruth label is equal to the predicted label.\n",
        "  return correct/len(gtlabel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGiA3LmDSJZo"
      },
      "source": [
        "In this lab, we will use the image pixels themselves as features, instead of extracting features. Each image has 28*28 pixels, so we will flatten them to 784 pixels to use as features. Note that this is very compute intensive and will take a long time.<br>\n",
        "\n",
        "Let us check the baseline accuracy on the test set without any augmentations. We hope that adding augmentations will help us to get better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tQvnoasRNEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff44330-151c-4d7a-beda-8842c053a882"
      },
      "source": [
        "testpred = NN(train_X, train_y, test_X)\n",
        "print('Baseline accuracy without augmentation is ', Accuracy(test_y, testpred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy without augmentation is  0.6472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfkcMfhIZQ7U"
      },
      "source": [
        "Let us try to improve this accuracy using augmentations. When we create augmentations, we have to make sure that the changes reflect what will naturally occur in the dataset. For example, we should not add colour to our samples as an augmentation because they do not naturally occur. We should not also flip the images in MNIST, because flipped images have different meanings for digits. \n",
        "\n",
        "### Augmentation 1: rotation\n",
        "\n",
        "Let us try rotating the image a little. We will use skimage library for this. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5WolJ9fZE7L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "8b07f9e8-02f1-403a-8505-8081ab5468a3"
      },
      "source": [
        "plt.imshow(train_X[2], cmap='gray')\n",
        "plt.show()\n",
        "plt.imshow(rotate(train_X[2],25), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc05b01a250>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE33Yxgggu0c"
      },
      "source": [
        "After rotating, the the class of the image is still the same. Let us make a function to rotate multiple images by random angles. We want a slightly different image every time we run this function. So, we generate a random number between 0 and 1 and change it so that it lies between -constraint/2 and +constraint/2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyM7pUV7Reze"
      },
      "source": [
        "def augRotate(sample, angleconstraint):\n",
        "  if angleconstraint==0:\n",
        "    return sample\n",
        "  if len(sample.shape)==2:\n",
        "    sample = np.expand_dims(sample, 0)  # make sure the sample is 3 dimensional\n",
        "  angle = rng.random(len(sample)) # generate random numbers for angles\n",
        "  angle = (angle-0.5)*angleconstraint # make the random angle constrained\n",
        "  nsample = sample.copy() # preallocate the augmented array to make it faster\n",
        "  for ii in range(len(sample)):\n",
        "    nsample[ii] = rotate(sample[ii], angle[ii])\n",
        "  return np.squeeze(nsample) # take care if the input had only one sample."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDk-N5VNjar9"
      },
      "source": [
        "This function returns a slightly different image each time we call it. So we can increase the number of images in the sample by any multiple. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw3O9zGFgI8K"
      },
      "source": [
        "sample = train_X[20]\n",
        "angleconstraint = 70\n",
        "# show the original image\n",
        "plt.imshow(sample, cmap='gray')\n",
        "plt.show()\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(augRotate(sample, angleconstraint), cmap='gray') # show an augmented image\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(augRotate(sample, angleconstraint), cmap='gray') # show another augmented image from the same sample\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(augRotate(sample, angleconstraint), cmap='gray') # one more image from the same sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytv3NxF-kgxN"
      },
      "source": [
        "Let us augment the whole dataset and see if this improves the test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNzNAoDBkRzj"
      },
      "source": [
        "# hyperparameters\n",
        "angleconstraint = 60\n",
        "naugmentations = 5\n",
        "\n",
        "# augment\n",
        "augdata = train_X # we include the original images also in the augmented dataset\n",
        "auglabel = train_y\n",
        "for ii in range(naugmentations):\n",
        "  augdata = np.concatenate((augdata, augRotate(train_X, angleconstraint))) # concatenate the augmented data to the set\n",
        "  auglabel = np.concatenate((auglabel, train_y))  # the labels don't change when we augment\n",
        "\n",
        "# check the test accuracy\n",
        "testpred = NN(augdata, auglabel, test_X)\n",
        "print('Accuracy after rotation augmentation is ', Accuracy(test_y, testpred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E88Nt9s1p5R6"
      },
      "source": [
        "The angle constraint is a hyperparameter which we have to tune using a validation set. (Here we are not doing that for time constraints). Let us try a grid search to find the best angle constraint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiaFRLREmGp6"
      },
      "source": [
        "angleconstraints = [0,10,20,30,40,50,60,70,80,90] # the values we want to test\n",
        "accuracies = np.zeros(len(angleconstraints), dtype=np.float) # we will save the values here\n",
        "\n",
        "for ii in range(len(angleconstraints)):\n",
        "  # create the augmented dataset\n",
        "  augdata = train_X # we include the original images also in the augmented dataset\n",
        "  auglabel = train_y\n",
        "  for jj in range(naugmentations):\n",
        "    augdata = np.concatenate((augdata, augRotate(train_X, angleconstraints[ii]))) # concatenate the augmented data to the set\n",
        "    auglabel = np.concatenate((auglabel, train_y))  # the labels don't change when we augment\n",
        "\n",
        "  # check the test accuracy\n",
        "  testpred = NN(augdata, auglabel, test_X)\n",
        "  accuracies[ii] = Accuracy(test_y, testpred)\n",
        "  print('Accuracy after rotation augmentation constrained by ',angleconstraints[ii], ' is ', accuracies[ii], flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oVDRYP2rxob"
      },
      "source": [
        "Let us see the best value for angle constraint: (Ideally this should be done on validation set, not test set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqthJa_pmMHz"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8]) # main axes\n",
        "# plot the variation of accuracy\n",
        "ax.plot(angleconstraints, accuracies)\n",
        "ax.set_xlabel('angle')\n",
        "ax.set_ylabel('accuracy')\n",
        "# plot the maximum accuracy\n",
        "maxind = np.argmax(accuracies)\n",
        "plt.scatter(angleconstraints[maxind], accuracies[maxind], c='red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ8YuVfCuGTj"
      },
      "source": [
        "Let us try one more augmentation: shear. Here is what this looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMiw46NLwssK"
      },
      "source": [
        "def shear(sample, amount):\n",
        "  tform = AffineTransform(shear = amount) # create the shear transform\n",
        "  img = warp(sample, tform) # apply the shear\n",
        "  # this makes the digit off-center. Since all the images in the test set are centralized, we will do the same here\n",
        "  col = img.sum(0).nonzero()[0]\n",
        "  row = img.sum(1).nonzero()[0]\n",
        "  if len(col)>0 and len(row)>0:\n",
        "    xshift = int(sample.shape[0]/2 - (row[0]+row[-1])/2)\n",
        "    yshift = int(sample.shape[1]/2 - (col[0]+col[-1])/2)\n",
        "    img = np.roll(img, (xshift, yshift),(0,1))\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_u_EYpmnABK"
      },
      "source": [
        "sample = train_X[2]\n",
        "plt.imshow(sample, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# apply shear\n",
        "plt.imshow(shear(sample, 0.4), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGnWMoyM2pK4"
      },
      "source": [
        "Create an augmentation function which applies a random shear according to the constraint we provide:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qLDJyGytwP5"
      },
      "source": [
        "def augShear(sample, shearconstraint):\n",
        "  if shearconstraint==0:\n",
        "    return sample\n",
        "  if len(sample.shape)==2:\n",
        "    sample = np.expand_dims(sample, 0)  # make sure the sample is 3 dimensional\n",
        "  amt = rng.random(len(sample)) # generate random numbers for shear\n",
        "  amt = (amt-0.5)*shearconstraint # make the random shear constrained\n",
        "  nsample = sample.copy() # preallocate the augmented array to make it faster\n",
        "  for ii in range(len(sample)):\n",
        "    nsample[ii] = shear(sample[ii], amt[ii])\n",
        "  return np.squeeze(nsample) # take care if the input had only one sample."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6lQcWW93suJ"
      },
      "source": [
        "Let us do a grid search to find the best shear constraint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_wrqPkrzBb_"
      },
      "source": [
        "shearconstraints = [0, 0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0] # the values we want to test\n",
        "accuracies = np.zeros(len(shearconstraints), dtype=np.float) # we will save the values here\n",
        "\n",
        "for ii in range(len(shearconstraints)):\n",
        "  # create the augmented dataset\n",
        "  augdata = train_X # we include the original images also in the augmented dataset\n",
        "  auglabel = train_y\n",
        "  for jj in range(naugmentations):\n",
        "    augdata = np.concatenate((augdata, augShear(train_X, shearconstraints[ii]))) # concatenate the augmented data to the set\n",
        "    auglabel = np.concatenate((auglabel, train_y))  # the labels don't change when we augment\n",
        "\n",
        "  # check the test accuracy\n",
        "  testpred = NN(augdata, auglabel, test_X)\n",
        "  accuracies[ii] = Accuracy(test_y, testpred)\n",
        "  print('Accuracy after shear augmentation constrained by ',shearconstraints[ii], ' is ', accuracies[ii], flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKaH-YR-zVnA"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8]) # main axes\n",
        "# plot the variation of accuracy\n",
        "ax.plot(shearconstraints, accuracies)\n",
        "ax.set_xlabel('angle')\n",
        "ax.set_ylabel('accuracy')\n",
        "# plot the maximum accuracy\n",
        "maxind = np.argmax(accuracies)\n",
        "plt.scatter(shearconstraints[maxind], accuracies[maxind], c='red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccfdbRcQ7Zgg"
      },
      "source": [
        "We can do multiple augmentations at the same time. Here is a function to do both shear and rotation to the sample. In this case, we will have two hyperparameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh8S_Pxa0XCv"
      },
      "source": [
        "def augRotateShear(sample, angleconstraint, shearconstraint):\n",
        "  if len(sample.shape)==2:\n",
        "    sample = np.expand_dims(sample, 0)  # make sure the sample is 3 dimensional\n",
        "  amt = rng.random(len(sample)) # generate random numbers for shear\n",
        "  amt = (amt-0.5)*shearconstraint # make the random shear constrained\n",
        "  angle = rng.random(len(sample)) # generate random numbers for angles\n",
        "  angle = (angle-0.5)*angleconstraint # make the random angle constrained\n",
        "  nsample = sample.copy() # preallocate the augmented array to make it faster\n",
        "  for ii in range(len(sample)):\n",
        "    nsample[ii] = rotate(shear(sample[ii], amt[ii]), angle[ii]) # first apply shear, then rotate\n",
        "  return np.squeeze(nsample) # take care if the input had only one sample."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGKyjjNx-NQ4"
      },
      "source": [
        "Since we have two hyperparameters, we have to do the grid search on a 2 dimensional matrix. We can use our previous experience to inform where to search for the best hyperparameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJC45WRg0pOP"
      },
      "source": [
        "shearconstraints = [0, 0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6] # the values we want to test\n",
        "angleconstraints = [0,10,20,30,40,50,60] # the values we want to test\n",
        "hyp = cartesian((shearconstraints, angleconstraints)) # cartesian product of both\n",
        "\n",
        "accuracies = np.zeros(len(hyp), dtype=np.float) # we will save the values here\n",
        "\n",
        "for ii in range(len(hyp)):\n",
        "  # create the augmented dataset\n",
        "  augdata = train_X # we include the original images also in the augmented dataset\n",
        "  auglabel = train_y\n",
        "  for jj in range(naugmentations):\n",
        "    augdata = np.concatenate((augdata, augRotateShear(train_X, hyp[ii][0], hyp[ii][1]))) # concatenate the augmented data to the set\n",
        "    auglabel = np.concatenate((auglabel, train_y))  # the labels don't change when we augment\n",
        "\n",
        "  # check the test accuracy\n",
        "  testpred = NN(augdata, auglabel, test_X)\n",
        "  accuracies[ii] = Accuracy(test_y, testpred)\n",
        "  print('Accuracy after augmentation shear:',hyp[ii][0], 'angle:',hyp[ii][1], ' is ', accuracies[ii], flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT6CnvSDEX7a"
      },
      "source": [
        "Let us plot it two dimensionally to see which is the best value for the hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD2i7msI_cLd"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8]) # main axes\n",
        "im = ax.imshow(accuracies.reshape((len(shearconstraints), len(angleconstraints))), cmap='inferno') \n",
        "ax.set_xlabel('angle')\n",
        "ax.set_ylabel('shear')\n",
        "ax.set_xticks(np.arange(len(angleconstraints)));\n",
        "ax.set_xticklabels(angleconstraints);\n",
        "ax.set_yticks(np.arange(len(shearconstraints)));\n",
        "ax.set_yticklabels(shearconstraints);\n",
        "plt.colorbar(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHcZWJiFJDMh"
      },
      "source": [
        "It seems that rotation and shear don't mix! The best accuracy is when rotation is zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAasQo1C3x4A"
      },
      "source": [
        "## Questions\n",
        "Try these questions for better understanding. You may not be able to solve all of them. \n",
        "1. What is the best value for angle constraint and shear constraint you got? How much did the accuracy improve as compared to not using augmentations?\n",
        "2. Can you increase the accuracy by increasing the number of augmentations from each sample?\n",
        "3. Try implementing a few augmentations of your own and experimenting with them. A good reference is <a href=https://www.analyticsvidhya.com/blog/2019/12/image-augmentation-deep-learning-pytorch/>here. </a>\n",
        "4. Try combining various augmentations. What is the highest accuracy you can get? What is the smallest training dataset you can take and still get accuracy above 50%?\n",
        "\n",
        "Whenever you do any experiment, a good practice is to vary the hyperparameters gradually and create a graph of your results, like we did for gridsearch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCzpwluJ46pI"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}